<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <!-- Main Step: Edit below title -->
    <title>CiteGuard: Faithful Citation Attribution for LLMs via Retrieval-Augmented Validation</title>

    <!-- SEO Meta Tags -->
    <meta name="description" content="" />
    <meta
      name="keywords"
      content="research papers, academic papers, AI research, robotics research, machine learning, published papers, scientific papers, academic journals"
    />
    <!-- <meta name="author" content="Research Paper Platform" />
    <meta name="robots" content="index, follow" />
    <meta
      name="robots"
      content="max-snippet:-1, max-image-preview:large, max-video-preview:-1"
    /> -->

    <!-- Open Graph Meta Tags (For Social Media Sharing) -->
    <!-- <meta
      property="og:title"
      content="Research Papers - Explore Cutting-Edge Research"
    />
    <meta
      property="og:description"
      content=""
    />
    <meta property="og:image" content="path-to-your-image.jpg" />
    <meta property="og:url" content="https://www.yourwebsite.com" />
    <meta property="og:type" content="website" />
    <meta property="og:site_name" content="Research Paper Platform" /> -->

    <!-- Twitter Meta Tags (For Twitter Sharing) -->
    <!-- <meta
      name="twitter:title"
      content="Research Papers - Explore Cutting-Edge Research"
    />
    <meta
      name="twitter:description"
      content=""
    />
    <meta name="twitter:image" content="path-to-your-image.jpg" />
    <meta name="twitter:card" content="summary_large_image" /> -->

    <!-- Canonical Link -->
    <!-- <link rel="canonical" href="https://www.yourwebsite.com" /> -->

    <!-- Favicon for different platforms -->
    <link
      rel="icon"
      href="Assets/Favicon/icons8-research-color-16.png"
      sizes="16x16"
      type="image/png"
    />
    <link
      rel="icon"
      href="Assets/Favicon/icons8-research-color-32.png"
      sizes="32x32"
      type="image/png"
    />
    <link
      rel="icon"
      href="Assets/Favicon/icons8-research-color-70.png"
      sizes="70x70"
      type="image/png"
    />
    <link
      rel="icon"
      href="Assets/Favicon/icons8-research-color-72.png"
      sizes="72x72"
      type="image/png"
    />
    <link
      rel="icon"
      href="Assets/Favicon/icons8-research-color-96.png"
      sizes="96x96"
      type="image/png"
    />

    <link rel="stylesheet" type="text/css" href="style.css" />
  </head>
  <body>
    <nav class="nav">
      <a href="#abstract">Abstract</a>
      <a href="#introduction">Introduction</a>
      <a href="#methodology">Methodology</a>
      <a href="#results">Results</a>
      <a href="#analysis">Analysis</a>
      <a href="#conclusion">Conclusion</a>
      <button class="toggle-btn" onclick="toggleDarkMode()">
        Toggle Dark Mode
      </button>
    </nav>

    <!-- Step 1 Start: Header Part -->

    <!-- 
    Remove if not applicable
    Edit below todo text
    Add URL link by removing # for each authers. Link can be GitHub, LinkedIn, Google Schooler, Website or other
    -->

    <div class="header">
      <h1>CiteGuard: Faithful Citation Attribution for LLMs via Retrieval-Augmented Validation</h1>
      <div class="authors">
        <p>
          <a href="#">Yee Man Choi</a><sup>1</sup>,
          <a href="#">Xuehang Guo</a><sup>2</sup>,
	  <a href="#">Yi R. (May) Fung</a><sup>3</sup>,
          <a href="#">Qingyun Wang</a><sup>2</sup>
        </p>
        <p>
          <sup>1</sup>University of Waterloo &nbsp;&nbsp; <sup>2</sup>College of William and Mary&nbsp;&nbsp; <sup>3</sup>Hong Kong University of Science and Technology
        </p>
        <p>
          <sup>1</sup
          >ymchoi@uwaterloo.ca,
          <sup>2</sup
	  >{xguo15,qwang16}@wm.edu,
	  <sup>3</sup>yrfung@ust.hk
        </p>
        <p>
        </p>
      </div>
    </div>

    <!-- Step 1 End: Header Part -->
    <!-- Step 2 Start: Button for links -->

    <!-- 
    Add URL links for each buttons according to name mentioned
    Remove # and add the link
    Add new button link if required
    Remove this step if not applicable
    -->

    <div class="buttons">
      <a href="#" target="_blank">Paper</a>
      <a href="#" target="_blank">Code</a>
      <a href="#bibtex">BibTex</a>
    </div>

    <!-- Step 2 End: Button for links -->

    <!-- Step 3 Start: Add your paper abstract -->

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    -->
    <div class="abstract" id="abstract">
      <h2>Abstract</h2>
      <p>Large Language Models (LLMs) have emerged as promising assistants for scientific writing. However, there have been concerns regarding the quality and reliability of the generated text, one of which is the citation accuracy and faithfulness. While most recent work relies on methods such as LLM-as-a-Judge, the reliability of LLM-as-a-Judge alone is also in doubt. In this work, we reframe citation evaluation as a problem of citation attribution alignment, which is assessing whether LLM-generated citations match those a human author would include for the same text. We propose <em>CiteGuard</em>, a retrieval-aware agent framework designed to provide more faithful grounding for citation validation. <em>CiteGuard</em> improves the prior baseline by 12.3%, and achieves up to 65.4% accuracy on the CiteME benchmark, on par with human-level performance (69.7%). It also enables the identification of alternative but valid citations.</p>
    </div>

    <!-- Step 3 End: Add your paper abstract -->

    <!-- Step 4 Start: Add your paper introduction -->

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    -->

    <div class="content-section" id="introduction">
      <h2>Introduction</h2>
      <p>We conduct an evaluation of the reliability of LLM-as-a-Judge for citation attribution of human-written scientific claims and their references.Although LLMs can recognize apparently incorrect citations, they often reject correct citations due to the lack of context in the field, resulting in a recall as low as 16-17%. </p>
    <style>
  table.citation-attribution {
    width: 100%;
    border-collapse: collapse;
    font-size: 0.9em;
    margin-bottom: 1em;
  }

  table.citation-attribution th,
  table.citation-attribution td {
    border: 1px solid #ccc;
    padding: 10px;
    text-align: center;
  }

  table.citation-attribution th:first-child,
  table.citation-attribution td:first-child {
    text-align: left;
  }

  table.citation-attribution caption {
    caption-side: bottom;
    font-style: italic;
    font-size: 0.85em;
    padding-top: 6px;
  }
</style>

<table class="citation-attribution">
  <thead>
    <tr>
      <th><strong>Method</strong></th>
      <th><strong>Precision</strong></th>
      <th><strong>Recall</strong></th>
      <th><strong>F1</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Zero-shot abstract</td>
      <td>1.0</td>
      <td>0.17</td>
      <td>0.29</td>
    </tr>
    <tr>
      <td>Few-shot abstract</td>
      <td>1.0</td>
      <td>0.16</td>
      <td>0.27</td>
    </tr>
    <tr>
      <td>Zero-shot full text</td>
      <td>1.0</td>
      <td>0.36</td>
      <td>0.53</td>
    </tr>
    <tr>
      <td>Few-shot full text</td>
      <td>1.0</td>
      <td>0.38</td>
      <td>0.55</td>
    </tr>
  </tbody>
  <caption>
    ChatGPT-4o accuracy on citation attribution in the CiteME benchmark.
  </caption>
</table>
<p>We propose <em>CiteGuard</em>, an agent that provides more faithful, and generalizable citation attribution through retrieval-augmented validation. Prior work, CiteAgent (<a href="https://www.citeme.ai/">Press et al., 2024</a>) aims to accurately cite scientific claims, although achieving accuracy higher than direct prompting, CiteAgent's accuracy (35.3%), is still not on par with human. We propose additional tools (i.e. to search for the context of the scientific claim and to perform a more robust search for paper content) and result in a +12.3% accuracy over CiteAgent under the same settings. When paired with Deepseek-R1, <em>CiteGuard</em> can achieve performance (65.4%) which matches that of a human (69.7%). Human evaluation indicates that <em>CiteGuard</em> can suggest additional citations that were missed by the original benchmark.
Our contributions are threefold:<ol>
	<li> We propose <em>CiteGuard</em>, an agent that provides faithful citation attribution by suggesting multiple appropriate references.</li>
	<li> We conduct detailed analysis on CiteME, and human annotations of alternative citations that is not captured by the current benchmark.</li>
	<li> We conduct experiments to show that <em>CiteGuard</em> significantly improves accuracy in finding the correct reference and that <em>CiteGuard</em> can suggest relevant alternative citations.</li></p>
    <table width=100%>
        <tr>
          <td width=30%><img src="citeagent_failures_cropped-1.png" alt="Image 1" style="max-width: 100%; height: auto;"></td>
          <td width=70%><img src="CiteGuard.png" alt="Image 2" style="max-width: 100%; height: auto;"></td>
        </tr>
      </table>

    </div>

    <!-- Step 4 End: Add your paper introduction -->

    <!-- Step 5 Start: Add your paper methodology -->

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    -->

    <div class="content-section" id="methodology">
      <h2>Methodology</h2>
      <p><em>CiteGuard</em> introduces new actions in addition to CiteAgent. We provide the set of actions below:</p>
      <ul>
        <li> (search_)citation_count/relevance (adopted)</li>
        <li> select (adopted)</li>
	<li> <b>find_in_text</b></li>
	<li> <b>ask_for_more_context</b></li>
	<li> <b>search_text_snippet</b></li>
      </ul>
      <div class="img"><img src="actions.png" alt="CiteGuard Actions" style="width:100%"></div>
    </div>

    <!-- Step 5 End: Add your paper methodology -->

    <!-- Step 6 Start: Add your paper results -->

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    Below have pre-build code for:
    -> 3 Images Carousel
    -> 3 Videos Carousel
    -> Single YouTube Video
    -> YouTube Video List
    If you do not need those, remove them.
    How to add YouTube Video:
    -> Go to the video page
    -> Click Share Button and Click <> Mark
    -> This will give <iframe></iframe> tag code
    -> Replace below <iframe></iframe> tag with your code
    -->

    <div class="content-section" id="results">
      <h2>Results</h2>
      <p>We evaluate <em>CiteGuard</em> on CiteME (<a href="https://www.citeme.ai/">Press et al., 2024</a>), which contains 130 excerpts collected from human-written manuscripts in different Computer Science domains (i.e. computer vision, natural language processing, algorithms, theory), where each excerpt contains exactly one missing citation. The task is for the LLM agent to suggest an appropriate paper to fill in the missing citation. <em>CiteGuard</em> substantially outperforms CiteAgent, improving the accuracy of retrieving the oracle citation by 12.3% on CiteME when both are powered by GPT-4o. When backed by open-source models DeepSeek-R1 and Kimi-K2, <em>CiteGuard</em> achieves up to 65.4% accuracy, approaching the 69.7% human performance reported in CiteME. This improvement is driven by <em>CiteGuard</em>’s extended retrieval actions, which makes citation search more flexible and robust. While CiteAgent relies heavily on the <em>read</em> action that assumes reliable PDF access, <em>CiteGuard</em> succeeds through introducing two key new actions:</p>
     <ul>
	<li><b>ask_for_more_context</b> that enables the agent to proactively query for additional claim context when the initial snippet is insufficient, and </li>
	<li><b>search_text_snippet</b> that allows searching directly within paper contents, thereby reducing reliance on PDF availability.
      </ul>
    <style>
  table.citeguard-table {
    width: 100%;
    border-collapse: collapse;
    font-size: 0.9em;
  }

  table.citeguard-table th,
  table.citeguard-table td {
    border: 1px solid #ccc;
    padding: 6px;
    text-align: center;
  }

  table.citeguard-table th:first-child,
  table.citeguard-table td:first-child {
    text-align: left;
  }

  table.citeguard-table caption {
    caption-side: bottom;
    font-style: italic;
    font-size: 0.85em;
    padding-top: 4px;
  }

  .bold {
    font-weight: bold;
  }

  .note {
    font-size: 0.85em;
  }
</style>

<table class="citeguard-table">
  <thead>
    <tr>
      <th></th>
      <th>Easy (%)</th>
      <th>Medium (%)</th>
      <th>Med-Hard (%)</th>
      <th>Hard (%)</th>
      <th>All (%)</th>
      <th>Agree (%)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>CiteAgent+GPT-4o</strong></td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>35.3<sup>*</sup></td>
      <td>-</td>
    </tr>
    <tr>
      <td><strong>CiteGuard+GPT-4o</strong></td>
      <td>100.0</td>
      <td>76.1</td>
      <td>12.8</td>
      <td>0.0</td>
      <td>47.7</td>
      <td>55.2</td>
    </tr>
    <tr>
      <td><strong>CiteGuard+DeepSeek-R1</strong></td>
      <td>100.0</td>
      <td>87.0</td>
      <td><strong>59.0</strong></td>
      <td>0.0</td>
      <td><strong>65.4</strong></td>
      <td>66.7</td>
    </tr>
    <tr>
      <td><strong>CiteGuard+Gemini</strong></td>
      <td>100.0</td>
      <td>43.5</td>
      <td>15.4</td>
      <td>0.0</td>
      <td>36.9</td>
      <td>40.6</td>
    </tr>
    <tr>
      <td><strong>CiteGuard+Kimi-K2</strong></td>
      <td>100.0</td>
      <td><strong>89.1</strong></td>
      <td>38.5</td>
      <td>0.0</td>
      <td>60.0</td>
      <td><strong>68.8</strong></td>
    </tr>
    <tr>
      <td><strong>CiteGuard+Qwen3</strong></td>
      <td>100.0</td>
      <td>65.2</td>
      <td>30.8</td>
      <td>0.0</td>
      <td>49.2</td>
      <td>62.5</td>
    </tr>
    <tr>
      <td><strong>Human</strong></td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td>-</td>
      <td><strong>69.7<sup>*</sup></strong></td>
      <td>-</td>
    </tr>
  </tbody>
  <caption>
    CiteGuard accuracy in the CiteME benchmark. “Agree” denotes the percentage of CiteGuard-suggested citations that human annotations agree are relevant. <span class="note">* denotes the number reported by CiteAgent (<a href="https://www.citeme.ai/">Press et al., 2024</a>).</span>
  </caption>
</table>
<p>Through manual assessment, <em>CiteGuard</em> showcases its ability to generate high-quality alternative citations beyond the original reference. Concretely, by using aggregated human annotations as a new oracle, we compute the agreement between <em>CiteGuard</em>’s suggested citations and human judgments. Across models, <em>CiteGuard</em> achieved substantial alignment with human evaluations, demonstrating its potential to identify relevant alternative literature. Notably, this ability is <b>model-agnostic</b>: both proprietary models like GPT-4o and open-source models like Qwen3 can effectively identify relevant alternatives.</p>
    </div>

    <!-- Step 6 End: Add your paper results -->

<div class="content-section" id="analysis">
      <h2>Analysis</h2>
      <h4>Retrieval vs Long-Context</h4>
      <p>To demonstrate the effect of retrieving only relevant parts of the paper versus providing the full paper text, we run the <em>CiteGuard</em>+Kimi-K2 agent, replacing the "find_in_text" action with the "read" action. With the "read" action, the accuracy increased by 3.07%, at the cost of 2%times more tokens. The number of tokens can be as large as 4%times. Although reading the full paper content in context can provide some benefits, it is at the cost of significantly more tokens. When using <em>CiteGuard</em>, users can determine whether to use retrieval or long-context based on the token budget.</p>
      <style>
  table.kimi-read-table {
    width: 100%;
    border-collapse: collapse;
    font-size: 0.9em;
  }

  table.kimi-read-table th,
  table.kimi-read-table td {
    border: 1px solid #ccc;
    padding: 6px;
    text-align: center;
  }

  table.kimi-read-table th:first-child,
  table.kimi-read-table td:first-child {
    text-align: left;
  }

  table.kimi-read-table caption {
    caption-side: bottom;
    font-style: italic;
    font-size: 0.85em;
    padding-top: 4px;
  }
</style>

<table class="kimi-read-table">
  <thead>
    <tr>
      <th><strong>Method</strong></th>
      <th><strong>Accuracy (%)</strong></th>
      <th><strong>Avg # of Tokens</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>read</strong></td>
      <td>60.0</td>
      <td>33,544.68</td>
    </tr>
    <tr>
      <td><strong>find_in_text</strong></td>
      <td>63.07</td>
      <td>15,451.43</td>
    </tr>
  </tbody>
  <caption>
    <em>CiteGuard</em>+Kimi-K2 accuracy difference on the CiteME benchmark when using different actions to get information from the paper content.
  </caption>
</table>

      <h4>Reasoning vs Non-Reasoning Models</h4>
      <p>The difference of open-sourced reasoning (DeepSeek-R1) and non-reasoning model (Kimi-K2) in overall performance is small (5.4%). A reasoning model tends to question itself (<em>"But note:...However,..."</em>) and consider other available actions in the reasoning phase, while a non-reasoning model would be more confident in its action (<em>"I can still be confident that..."</em>). Although the agent backed by both models eventually arrived at different citations, both are correct through human assessment, demonstrating that <em>CiteGuard</em> is not dependent on reasoning ability.</p>
      <style>
  .text-box {
    border: 1px solid #ccc;
    background-color: #f9f9f9;
    padding: 16px;
    border-radius: 8px;
    font-family: sans-serif;
    font-size: 0.95em;
    line-height: 1.5;
    margin-bottom: 1.5em;
  }

  .text-box h4 {
    margin-top: 0;
    font-size: 1em;
    font-weight: bold;
    color: #333;
    border-bottom: 1px solid #ddd;
    padding-bottom: 4px;
  }

  .response-block {
    margin-top: 1em;
  }

  .model-name {
    font-weight: bold;
    color: #2c3e50;
    margin-bottom: 0.3em;
  }

  .model-response {
    white-space: pre-line;
    background-color: #fff;
    padding: 10px 12px;
    border: 1px solid #e0e0e0;
    border-radius: 6px;
  }
</style>

<div class="text-box">
  <h4>Excerpt</h4>
  <div>
    A second consideration is how to treat the image itself: the raw image could be fed directly into the reinforcement learning algorithm through a series of convolutions <em>[CITATION]</em>.
  </div>

  <div class="response-block">
    <div class="model-name">DeepSeek-R1:</div>
    <div class="model-response">
...But note: the excerpt says "the raw image could be fed directly into the reinforcement learning algorithm through a series of convolutions". This is exactly what DQN did. However, let's break it down:
- The citation is likely for the method of using convolutions to process raw images in RL, not necessarily the entire RL algorithm...
    </div>
  </div>

  <div class="response-block">
    <div class="model-name">Kimi-K2:</div>
    <div class="model-response">
...I can still be confident that its abstract already declares it is the first deep learning model to successfully learn control policies directly from high-dimensional sensory input, where input is raw pixels...
    </div>
  </div>
</div>

      <h4>CiteGuard vs Paper Finders</h4>
      <p>An alternative to finding potential references using <em>CiteGuard</em> is to use a paper finder. We run <a href="https://asta.allen.ai/chat">Ai2 Paper Finder</a> on CiteME and present the results. We argue that <em>CiteGuard</em> matches Paper Finder in terms of accuracy, if not surpasses it. In particular, the top 10 accuracy is 5.4 percentage points below the top 1 accuracy of CiteGuard+DeepSeek-R1, demonstrating that <em>CiteGuard</em> is more reliable, which is likely because it incorporates the context of the excerpt.</p>
    </div>

    <!-- Step 7 Start: Add your paper conclusion -->
<style>
  table.paper-finder-table {
    width: 100%;
    border-collapse: collapse;
    font-size: 0.9em;
  }

  table.paper-finder-table th,
  table.paper-finder-table td {
    border: 1px solid #ccc;
    padding: 6px;
    text-align: center;
  }

  table.paper-finder-table th:first-child,
  table.paper-finder-table td:first-child {
    text-align: left;
  }

  table.paper-finder-table caption {
    caption-side: bottom;
    font-style: italic;
    font-size: 0.85em;
    padding-top: 4px;
  }
</style>

<table class="paper-finder-table">
  <thead>
    <tr>
      <th></th>
      <th><strong>Top 1</strong></th>
      <th><strong>Top 5</strong></th>
      <th><strong>Top 10</strong></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>AI2 Paper Finder</strong></td>
      <td>38.5</td>
      <td>55.4</td>
      <td>60.0</td>
    </tr>
    <tr>
      <td><strong>Ours+Gemini</strong></td>
      <td>36.9</td>
      <td>-</td>
      <td>-</td>
    </tr>
    <tr>
      <td><strong>Ours+DeepSeek-R1</strong></td>
      <td><strong>65.4</strong></td>
      <td>-</td>
      <td>-</td>
    </tr>
  </tbody>
  <caption>
    AI2 Paper Finder (<a href="https://asta.allen.ai/chat">AI2</a>) accuracy (%) on CiteME compared to CiteGuard.
  </caption>
</table>

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    -->

    <div class="content-section" id="conclusion">
      <h2>Conclusion</h2>
      <p>We observe the limitation in using LLM-as-a-Judge for citation attribution of scientific writing and propose CiteGuard agent to provide a more faithful citation attribution through retrieval-augmented validation. We show the reliability of CiteGuard in finding correct citations to be on par with humans, and the alternative citations suggested by CiteGuard are deemed relevant by human annotators.</p>
    </div>

    <!-- Step 7 End: Add your paper conclusion -->

    <!-- Step 8 Start: Add your paper references -->

    <!-- 
    Please only edit below between CODE tags - TODOs
    Remove this step if not applicable
    -->

    <div class="bibtex-section" id="bibtex">
      <h2>BibTeX</h2>
      <button class="bibtex-copy-button" onclick="copyBibTeX()">
        Copy to Clipboard
      </button>
      <pre>
        <!-- Please edit only below details -->
        <code class="language-bibtex">
          @inproceedings{TODO: YourPaperCitation,
            title={TODO: Paper Title},
            author={[TODO: Author Names]},
            booktitle={[TODO: Conference Name]},
            year={TODO: 2024},
            pages={[pages]}
          }
        </code>
      </pre>
    </div>

    <!-- Step 8 End: Add your paper references -->

    <!-- Step 9 Start: Add your paper acknowledgement -->

    <!-- 
    Please do not remove below H2 heading tag. Add your HTML code after H2 HTML tag or add text inside P HTML tag. 
    Remove this step if not applicable
    -->

    <div class="content-section" id="acknowledgement">
      <h2>Acknowledgement</h2>
      <p>Gemini Developer API</p>
    </div>

    <!-- Step 9 End: Add your paper acknowledgement -->

    <div class="footer">
      <!-- Step 10 Start: Edit footer -->
      <p>© 2024 [University of Waterloo]. All rights reserved.</p>
      <!-- Step 10 End: Edit footer -->
      <!-- Please do not remove below code. -->
      <p>
        Website template free to borrow from
        <a
          href="https://github.com/indramal/iNdra-GitHub-Page-Template-For-Resarch"
          >here</a
        >.
      </p>
       <div>
</div>

    <!-- Do not edit below button -->
    <button class="scrollUpBtn" id="scrollUpBtn" onclick="scrollToTop()">
      ⬆
    </button>

    <script src="script.js"></script>
  </body>
</html>
